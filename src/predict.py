"""
Fonctions de pr√©diction d'√©motions
===================================

Fonctions utilitaires pour pr√©dire les √©motions dans un texte.
"""

import tensorflow as tf
import os
from typing import Tuple, List, Optional

from .model import EmotionClassifier
from .config import LABEL_NAMES, DEFAULT_THRESHOLD


# Instance globale du mod√®le (charg√©e une seule fois)
_classifier_instance: Optional[EmotionClassifier] = None


def get_classifier() -> EmotionClassifier:
    """
    Retourne l'instance unique du classificateur (singleton pattern).
    
    Charge le mod√®le une seule fois et le r√©utilise ensuite.
    
    Returns:
        EmotionClassifier: Instance du mod√®le charg√©.
    """
    global _classifier_instance
    
    if _classifier_instance is None:
        print("Initialisation du mod√®le (premi√®re utilisation)...")
        _classifier_instance = EmotionClassifier()
        _classifier_instance.load_weights()
        print("Mod√®le pr√™t √† l'emploi!")
    
    return _classifier_instance


def predict_emotions(
    text: str,
    threshold: float = DEFAULT_THRESHOLD,
    return_all: bool = False
) -> Tuple[List[Tuple[str, float]], List[float]]:
    """
    Pr√©dit les √©motions pr√©sentes dans un texte.
    
    Cette fonction analyse un texte en anglais et retourne les √©motions
    d√©tect√©es avec leur probabilit√© (en pourcentage).
    
    Le mod√®le peut d√©tecter plusieurs √©motions simultan√©ment (multi-label).
    
    Args:
        text: Texte √† analyser (en anglais de pr√©f√©rence).
        threshold: Seuil de probabilit√© (0.0 √† 1.0).
                   Les √©motions au-dessus de ce seuil sont retourn√©es.
                   D√©faut: 0.50 (50%).
        return_all: Si True, retourne aussi toutes les probabilit√©s brutes.
    
    Returns:
        Tuple contenant:
        - detected_emotions: Liste de tuples (√©motion, probabilit√©%)
                            tri√©e par probabilit√© d√©croissante.
        - all_probs: Liste de 28 probabilit√©s (une par √©motion) en %.
    
    Example:
        >>> emotions, probs = predict_emotions("I am so happy!", threshold=0.5)
        >>> print(emotions)
        [('joy', 91.2), ('excitement', 82.5)]
        
        >>> # Texte avec √©motions multiples
        >>> emotions, _ = predict_emotions("I'm sad but also hopeful", threshold=0.4)
        >>> print(emotions)
        [('sadness', 87.3), ('optimism', 62.1)]
    
    Notes:
        - Le mod√®le ne d√©tecte PAS l'intensit√© des √©motions (a little, very, etc.)
        - Fonctionne mieux avec des textes courts √† moyens (<500 mots)
        - Entra√Æn√© sur du texte anglais, peut avoir des r√©sultats variables sur d'autres langues
    """
    # Charger le mod√®le (singleton, charg√© une seule fois)
    classifier = get_classifier()
    
    # Pr√©diction (logits bruts)
    logits = classifier.predict([text], verbose=0)
    
    # Appliquer sigmoid pour obtenir les probabilit√©s (0 √† 1)
    probs = tf.nn.sigmoid(logits[0]).numpy()
    
    # Convertir en pourcentage
    probs_percent = probs * 100
    
    # Filtrer les √©motions au-dessus du seuil
    detected_emotions = []
    for idx, prob in enumerate(probs):
        if prob >= threshold:
            detected_emotions.append((LABEL_NAMES[idx], probs_percent[idx]))
    
    # Trier par probabilit√© d√©croissante
    detected_emotions.sort(key=lambda x: x[1], reverse=True)
    
    if return_all:
        return detected_emotions, probs_percent.tolist()
    else:
        return detected_emotions, probs_percent.tolist()


def predict_emotions_batch(
    texts: List[str],
    threshold: float = DEFAULT_THRESHOLD
) -> List[List[Tuple[str, float]]]:
    """
    Pr√©dit les √©motions pour plusieurs textes en une seule fois (batch).
    
    Plus efficace que d'appeler predict_emotions() en boucle.
    
    Args:
        texts: Liste de textes √† analyser.
        threshold: Seuil de probabilit√© pour la d√©tection.
    
    Returns:
        Liste de listes de tuples (√©motion, probabilit√©%) pour chaque texte.
    
    Example:
        >>> texts = ["I am happy", "I am sad", "I am angry"]
        >>> results = predict_emotions_batch(texts, threshold=0.5)
        >>> for i, emotions in enumerate(results):
        ...     print(f"{texts[i]}: {emotions}")
    """
    classifier = get_classifier()
    
    # Pr√©diction batch
    logits = classifier.predict(texts, verbose=0)
    probs = tf.nn.sigmoid(logits).numpy()
    probs_percent = probs * 100
    
    # Extraire les √©motions pour chaque texte
    all_results = []
    for text_probs in probs:
        detected = []
        for idx, prob in enumerate(text_probs):
            if prob >= threshold:
                detected.append((LABEL_NAMES[idx], probs_percent[len(all_results)][idx]))
        detected.sort(key=lambda x: x[1], reverse=True)
        all_results.append(detected)
    
    return all_results


def get_emotion_names() -> List[str]:
    """
    Retourne la liste des 28 √©motions d√©tectables.
    
    Returns:
        Liste des noms d'√©motions.
    """
    return LABEL_NAMES.copy()


def format_results(emotions: List[Tuple[str, float]], top_n: int = 5) -> str:
    """
    Formate joliment les r√©sultats de pr√©diction.
    
    Args:
        emotions: Liste de tuples (√©motion, probabilit√©%).
        top_n: Nombre d'√©motions √† afficher (d√©faut: 5).
    
    Returns:
        Cha√Æne format√©e avec les √©motions et leurs probabilit√©s.
    
    Example:
        >>> emotions, _ = predict_emotions("I am happy!")
        >>> print(format_results(emotions))
        üé≠ √âmotions d√©tect√©es:
          1. joy          : 91.2%
          2. excitement   : 82.5%
    """
    if not emotions:
        return "üé≠ Aucune √©motion d√©tect√©e au-dessus du seuil."
    
    result = "üé≠ √âmotions d√©tect√©es:\n"
    for i, (emotion, prob) in enumerate(emotions[:top_n], 1):
        result += f"  {i}. {emotion:15s} : {prob:.1f}%\n"
    
    return result.rstrip()
