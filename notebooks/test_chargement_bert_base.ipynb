{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6fe7b93",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emerickmiatti/Development/Formation IA/Projet/Emosens/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras_nlp\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3327aee3",
   "metadata": {},
   "source": [
    "## 1. Charger le modèle BERT Base sauvegardé"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df4a497c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modèle chargé !\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emerickmiatti/Development/Formation IA/Projet/Emosens/.venv/lib/python3.11/site-packages/keras/src/saving/saving_lib.py:797: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 404 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    }
   ],
   "source": [
    "MODEL_PATH = '../models/bert_base_20251213_170236.weights.h5'\n",
    "PRESET = 'bert_base_en_uncased'\n",
    "NUM_CLASSES = 28\n",
    "SEQUENCE_LENGTH = 128\n",
    "\n",
    "classifier = keras_nlp.models.BertClassifier.from_preset(\n",
    "    PRESET,\n",
    "    num_classes=NUM_CLASSES\n",
    ")\n",
    "classifier.preprocessor.sequence_length = SEQUENCE_LENGTH\n",
    "classifier.load_weights(MODEL_PATH)\n",
    "print('Modèle chargé !')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5772c41",
   "metadata": {},
   "source": [
    "## 2. Tester l'inférence sur des exemples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "865d2af5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texte : I am so happy and excited!\n",
      "  • excitement      : 97.0%\n",
      "  • joy             : 93.4%\n",
      "----------------------------------------\n",
      "Texte : This is the worst experience ever. I'm so disappointed.\n",
      "  • disappointment  : 96.4%\n",
      "  • sadness         : 83.1%\n",
      "  • embarrassment   : 75.5%\n",
      "  • disgust         : 74.3%\n",
      "  • annoyance       : 54.9%\n",
      "----------------------------------------\n",
      "Texte : I'm sad but also optimistic about the future.\n",
      "  • sadness         : 95.7%\n",
      "  • disappointment  : 63.9%\n",
      "  • optimism        : 56.5%\n",
      "  • grief           : 42.3%\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "LABEL_NAMES = [\n",
    "    'admiration', 'amusement', 'anger', 'annoyance', 'approval', 'caring',\n",
    "    'confusion', 'curiosity', 'desire', 'disappointment', 'disapproval',\n",
    "    'disgust', 'embarrassment', 'excitement', 'fear', 'gratitude', 'grief',\n",
    "    'joy', 'love', 'nervousness', 'optimism', 'pride', 'realization',\n",
    "    'relief', 'remorse', 'sadness', 'surprise', 'neutral'\n",
    "]\n",
    "\n",
    "def predict_emotions(text, threshold=0.5):\n",
    "    logits = classifier.predict([text], verbose=0)\n",
    "    probs = tf.nn.sigmoid(logits[0]).numpy()\n",
    "    probs_percent = probs * 100\n",
    "    detected = [(LABEL_NAMES[i], probs_percent[i]) for i in range(len(LABEL_NAMES)) if probs[i] >= threshold]\n",
    "    detected.sort(key=lambda x: x[1], reverse=True)\n",
    "    return detected, probs_percent\n",
    "\n",
    "# Exemples\n",
    "examples = [\n",
    "    \"I am so happy and excited!\",\n",
    "    \"This is the worst experience ever. I'm so disappointed.\",\n",
    "    \"I'm sad but also optimistic about the future.\"\n",
    "]\n",
    "\n",
    "for text in examples:\n",
    "    emotions, probs = predict_emotions(text, threshold=0.4)\n",
    "    print(f'Texte : {text}')\n",
    "    if emotions:\n",
    "        for emotion, prob in emotions:\n",
    "            print(f'  • {emotion:15s} : {prob:.1f}%')\n",
    "    else:\n",
    "        print('  Aucune émotion détectée au-dessus du seuil.')\n",
    "    print('-'*40)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
